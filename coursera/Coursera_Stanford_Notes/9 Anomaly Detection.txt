	***Anomaly Detection - Problem motivation*** - Vid 1 - Week 9***
Anomaly a test set data point that results being outside of expected behaviour when comparing 
related features. 

Density Estimation:
See screenshot below for comparing the heat and vibrations of a plane engine:

w9 - Desnity Estimation 

note: p(x) is the probability that each data point will occur

w9 - AnomalyDetection_Examples

Gaussian (Normal) Distribution

See screenshot: w9 - Gaussian (Normal) Distribution

	***Anomaly Detection - Algorithm*** - Vid 2 - Week 9***

See screenshot: w9 - AD_Algorithm

	***Anomaly Detection - Developing and Evaluating an Anomaly Detection System*** - Vid 3 - Week 9***

See screenshot: w9 - AD_AlgorithmEvaluation

	***Anomaly Detection - Anomaly Detection Vs. Supervised Learning*** - Vid 4 - Week 9***

See screenshot: w9 - Difference_AnomalyDetectVs.SuperLearn

	***Anomaly Detection - Anomaly Detection Choosing What Features to Use*** - Vid 5 - Week 9***

If data is not in the normal distribution form, we can transform the data using log(x).

See screenshot: w9 - AD - Transform_G(N)D

See screenshot: w9 - AD - ErrorAnal

Examples of features for monitoring computers in a data center. 

Choose features that will take on very large or very small values in the event of an anomaly. 

x_1 = memory use of a computer
x_2 = number of disk accesses/sec
x_3 = CPU load
x_4 = network traffic

Suspicion: one of the failure cases is that a computer has a job that gets stuck in an infinite loop. 
In this case, CPU grows but network traffic stays the same. 

So we come up with another feature:

x_5 = (CPU load / network traffic)
x_6 = ((CPU load)^2 / network traffic)

This can help us understand data points that take on unusual values, 
and can possibly be extremely relevant for our model. We use this to try and catch anomalies.

	***Anomaly Detection - Anomaly Detection Choosing What Features to Use*** - Vid 6 - Week 9***
	
	
	
	***Anomaly Detection - Recommender Systems: Problem Formulation*** - Vid 7 - Week 9***

We can use recommender systems for learning the recommended features, x^(i)

See screenshot: w9 - AD - PredictingMovieRatings

Need an algorithm that can predict which movies the use should watch. 
-Movies that haven't been seen yet, that fall within their star value (like). 
-Predicts what the unseen movie will be rated by the user.

See screenshot: w9 - AD - ProblemFormation_VariablesDef

See screenshot: w9 - AD - ProblemFormation_OptimizationAlgo_*Code

Content Based approach -in our example: we have features that capture the content of these movies

	***Anomaly Detection - Recommender Systems: Collaborative Learning*** - Vid 8 - Week 9***
	
See screenshot: w9 - AD - CollaborativeFiltering_Outline

	***Anomaly Detection - Recommender Systems: Collaborative Learning Algorithm*** - Vid 8 - Week 9***

Instead of solving for x and theta independently we are going to construct an algorithm that
solves for both simultaneously. 

See screenshot: w9 - AD - CollaborativeFiltering_1Outline

See screenshot: w9 - AD - CollaborativeFiltering_2Objective

See screenshot: w9 - AD - CollaborativeFiltering_3Algorithm

By solving simultaneously, we are able to find both x and theta, however, trying to compute the other way, 
it would take much longer and be inefficient code. 

	***AD - Recommender Systems: Vectorization: Low Rank Matrix Factorization*** - Vid 9 - Week 9***

Now we will talk about the vectorization of the recommender systems algorithm. 

See screenshot: w9 - AD - CollaborativeFiltering_4Vectorization

See screenshot: w9 - AD - CollaborativeFiltering_4Example

Based on movie j, how would we find a similar movie, i, that the user would like?

The reason it doesn't matter if it is classified as a romance, action, etc. features, 
is because the algorithm just has to find related movies to that based off of users data, 
rather the smallest distance to the actual values of other movies. 

	***AD - Recommender Systems: Implementation Detail: Mean Normalization*** - Vid 10 - Week 9***

Last Detail, mean normalization which can just make the algorithm look a little bit better. 

For someone who hasn't inputted any data:

1. Take matrix (Y) of all users input into movies
2. Take means (meu, m) of movie ratings including all users who have inputted data.
3. Subtract Y-m to get a new matrix that then will be used to learn parameters (theta) and features (x) for J

See screenshot: w9 - AD - CollaborativeFiltering_4MeanNormalization

This explains that we calculate just the average of all movies ratings and then use 
mean normalization (take the matrix of all values and subtract the average of all those values). 
This can be used to find the values for users who have never inputted data (rated a movie with stars).



























































